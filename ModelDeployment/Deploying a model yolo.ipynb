{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azurewrapper.workspace import get_workspace\n",
    "\n",
    "# subscription_id = \"29d66431-a7ce-4709-93f7-3bdb01a243b3\"\n",
    "# resource_group = \"ExperimentationJayke\"\n",
    "# workspace_name = \"ExperimentationJayke\"\n",
    "subscription_id = \"a00eaec6-b320-4e7c-ae61-60a30aec1cfc\"\n",
    "resource_group = \"MachineLearning\"\n",
    "workspace_name = \"RiverImageAnalysis\"\n",
    "tenant_id = \"86f9fea7-9eb0-4325-8b58-7ed0db623956\"\n",
    "\n",
    "workspace = get_workspace(subscription_id, resource_group, workspace_name, tenant_id=tenant_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "model = Model(workspace, \"yolo_v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No environment with that name found, creating new one\n"
     ]
    }
   ],
   "source": [
    "from azurewrapper.environment import get_environment\n",
    "\n",
    "environment = get_environment(\n",
    "    workspace,\n",
    "    \"tensorflow-yolo\",\n",
    "    pip_requirements=\"./examples/yolo/Tensorflow_YOLO/requirements.txt\",\n",
    "    docker_image=\"mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model yolo_v4:2 to /tmp/azureml_4jc88r0l/yolo_v4/2\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry 0ea7be47d3e548c3bd0de28701c8bddf.azurecr.io\n",
      "Logging into Docker registry 0ea7be47d3e548c3bd0de28701c8bddf.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM 0ea7be47d3e548c3bd0de28701c8bddf.azurecr.io/azureml/azureml_ea71d6d6fbafdaeb54907902a21c77dc\n",
      " ---> 858c385d508a\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> e838e06b60fd\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6ImEwMGVhZWM2LWIzMjAtNGU3Yy1hZTYxLTYwYTMwYWVjMWNmYyIsInJlc291cmNlR3JvdXBOYW1lIjoibWFjaGluZWxlYXJuaW5nIiwiYWNjb3VudE5hbWUiOiJyaXZlcmltYWdlYW5hbHlzaXMiLCJ3b3Jrc3BhY2VJZCI6IjBlYTdiZTQ3LWQzZTUtNDhjMy1iZDBkLWUyODcwMWM4YmRkZiJ9LCJtb2RlbHMiOnt9LCJtb2RlbHNJbmZvIjp7fX0= | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in 21788c2e63c6\n",
      " ---> 4e8c6a820abf\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmphyluykb3.py' /var/azureml-app/main.py\n",
      " ---> Running in d7d6155a53bf\n",
      " ---> b0e7293013b8\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in 2fca69783498\n",
      " ---> 27a12f0d2bea\n",
      "Successfully built 27a12f0d2bea\n",
      "Successfully tagged testdeploy1:latest\n",
      "Container (name:sharp_leakey, id:17962e6e6d7a7e9832ac423bca3566f4761241ebfa36622cb533378e5d97c5a1) cannot be killed.\n",
      "Container has been successfully cleaned up.\n",
      "Image sha256:ae0ebc2020f40a417082394969f1a4c8287ebf09cb9b69b533e0346ec6d9d1fe successfully removed.\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR - Error: Container has crashed. Did your init method fail?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Container Logs:\n",
      "2020-11-12T16:38:26,530762818+00:00 - gunicorn/run \n",
      "2020-11-12T16:38:26,530462418+00:00 - iot-server/run \n",
      "2020-11-12T16:38:26,530775186+00:00 - rsyslog/run \n",
      "2020-11-12T16:38:26,804977295+00:00 - nginx/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2020-11-12T16:38:31,177043078+00:00 - iot-server/finish 1 0\n",
      "2020-11-12T16:38:31,179233721+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (7)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 45\n",
      "2020-11-12 16:38:38.591506: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2020-11-12 16:39:01,696 | root | INFO | Starting up app insights client\n",
      "Starting up app insights client\n",
      "2020-11-12 16:39:01,696 | root | INFO | Starting up request id generator\n",
      "Starting up request id generator\n",
      "2020-11-12 16:39:01,696 | root | INFO | Starting up app insight hooks\n",
      "Starting up app insight hooks\n",
      "2020-11-12 16:39:01,696 | root | INFO | Invoking user's init function\n",
      "Invoking user's init function\n",
      "2020-11-12 16:39:01.783373: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_431acb06527d440db41918b00defd142/lib:/azureml-envs/azureml_431acb06527d440db41918b00defd142/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2020-11-12 16:39:01.783416: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2020-11-12 16:39:01.783461: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2020-11-12 16:39:02.202638: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3502745000 Hz\n",
      "2020-11-12 16:39:02.203296: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559a4723e510 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-11-12 16:39:02.203328: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "!!!!!!!!!!!!!!!!!!!!!!INIT!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "['outputs']\n",
      "!!!!!!!!!!!!!!!!!!!YOLO CREATED!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "From /azureml-envs/azureml_431acb06527d440db41918b00defd142/lib/python3.6/site-packages/tensorflow/python/training/tracking/util.py:1298: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.\n",
      "2020-11-12 16:39:03,746 | root | ERROR | User's init function failed\n",
      "User's init function failed\n",
      "2020-11-12 16:39:03,788 | root | ERROR | Encountered Exception Traceback (most recent call last):\n",
      "  File \"/var/azureml-server/aml_blueprint.py\", line 187, in register\n",
      "    main.init()\n",
      "  File \"/var/azureml-app/yolo/score.py\", line 29, in init\n",
      "    'outputs/labels.names'\n",
      "  File \"/var/azureml-app/yolo/Tensorflow_YOLO/yolov3/utils.py\", line 86, in Load_Yolo_model_custom\n",
      "    yolo.load_weights(weights, by_name=True) # use custom weights\n",
      "  File \"/azureml-envs/azureml_431acb06527d440db41918b00defd142/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 2185, in load_weights\n",
      "    'Weights may only be loaded based on topology into Models when '\n",
      "NotImplementedError: Weights may only be loaded based on topology into Models when loading TensorFlow-formatted weights (got by_name=True to load_weights).\n",
      "\n",
      "Encountered Exception Traceback (most recent call last):\n",
      "  File \"/var/azureml-server/aml_blueprint.py\", line 187, in register\n",
      "    main.init()\n",
      "  File \"/var/azureml-app/yolo/score.py\", line 29, in init\n",
      "    'outputs/labels.names'\n",
      "  File \"/var/azureml-app/yolo/Tensorflow_YOLO/yolov3/utils.py\", line 86, in Load_Yolo_model_custom\n",
      "    yolo.load_weights(weights, by_name=True) # use custom weights\n",
      "  File \"/azureml-envs/azureml_431acb06527d440db41918b00defd142/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 2185, in load_weights\n",
      "    'Weights may only be loaded based on topology into Models when '\n",
      "NotImplementedError: Weights may only be loaded based on topology into Models when loading TensorFlow-formatted weights (got by_name=True to load_weights).\n",
      "\n",
      "Worker exiting (pid: 45)\n",
      "Shutting down: Master\n",
      "Reason: Worker failed to boot.\n",
      "2020-11-12T16:39:05,486582087+00:00 - gunicorn/finish 3 0\n",
      "2020-11-12T16:39:05,488037068+00:00 - Exit code 3 is not normal. Killing image.\n",
      "\n"
     ]
    },
    {
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: Error: Container has crashed. Did your init method fail?\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Error: Container has crashed. Did your init method fail?\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6f388d416df5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0menvironment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_deployment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/toc_azureml/lib/python3.6/site-packages/azureml/core/webservice/local.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 raise WebserviceException('Cannot call {}() when service is {}.'.format(func.__name__, self.state),\n\u001b[1;32m     70\u001b[0m                                           logger=module_logger)\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/toc_azureml/lib/python3.6/site-packages/azureml/core/webservice/local.py\u001b[0m in \u001b[0;36mwait_for_deployment\u001b[0;34m(self, show_output)\u001b[0m\n\u001b[1;32m    601\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                                    \u001b[0mhealth_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_base_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m                                    cleanup_if_failed=False)\n\u001b[0m\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocalWebservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTATE_RUNNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/toc_azureml/lib/python3.6/site-packages/azureml/_model_management/_util.py\u001b[0m in \u001b[0;36mcontainer_health_check\u001b[0;34m(docker_port, container, health_url, cleanup_if_failed)\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0;31m# The container has started and crashed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m             _raise_for_container_failure(container, cleanup_if_failed,\n\u001b[0;32m--> 741\u001b[0;31m                                          'Error: Container has crashed. Did your init method fail?')\n\u001b[0m\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;31m# The container hasn't crashed, so try to ping the health endpoint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/toc_azureml/lib/python3.6/site-packages/azureml/_model_management/_util.py\u001b[0m in \u001b[0;36m_raise_for_container_failure\u001b[0;34m(container, cleanup, message)\u001b[0m\n\u001b[1;32m   1252\u001b[0m         \u001b[0mcleanup_container\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mWebserviceException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule_logger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Error: Container has crashed. Did your init method fail?\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Error: Container has crashed. Did your init method fail?\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "from azurewrapper.deploy import deploy\n",
    "service = deploy(\n",
    "    workspace,\n",
    "    \"testdeploy1\",\n",
    "    model,\n",
    "    \"score.py\",\n",
    "    \"examples/yolo\",\n",
    "    environment=environment,\n",
    ")\n",
    "service.wait_for_deployment(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container has been successfully cleaned up.\n",
      "Starting Docker container...\n",
      "Docker container running.\n"
     ]
    }
   ],
   "source": [
    "service.reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-11-12T17:15:27,624050294+00:00 - iot-server/run \\n2020-11-12T17:15:27,625413175+00:00 - rsyslog/run \\n2020-11-12T17:15:27,627167282+00:00 - gunicorn/run \\n2020-11-12T17:15:27,629166198+00:00 - nginx/run \\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\nStarting gunicorn 19.9.0\\nListening at: http://127.0.0.1:31311 (12)\\nUsing worker: sync\\nworker timeout is set to 300\\nBooting worker with pid: 41\\n2020-11-12T17:15:28,758996899+00:00 - iot-server/finish 1 0\\n2020-11-12T17:15:28,760590561+00:00 - Exit code 1 is normal. Not restarting iot-server.\\n2020-11-12 17:15:29.076269: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\\nSPARK_HOME not set. Skipping PySpark Initialization.\\nInitializing logger\\n2020-11-12 17:15:30,493 | root | INFO | Starting up app insights client\\nStarting up app insights client\\n2020-11-12 17:15:30,494 | root | INFO | Starting up request id generator\\nStarting up request id generator\\n2020-11-12 17:15:30,494 | root | INFO | Starting up app insight hooks\\nStarting up app insight hooks\\n2020-11-12 17:15:30,494 | root | INFO | Invoking user\\'s init function\\nInvoking user\\'s init function\\n2020-11-12 17:15:30.494590: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library \\'libcuda.so.1\\'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_431acb06527d440db41918b00defd142/lib:/azureml-envs/azureml_431acb06527d440db41918b00defd142/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64\\n2020-11-12 17:15:30.494610: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\\n2020-11-12 17:15:30.494636: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\\n2020-11-12 17:15:30.538623: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3502745000 Hz\\n2020-11-12 17:15:30.539287: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555dcabf1a40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\\n2020-11-12 17:15:30.539332: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\\n[\\'outputs\\']\\n2020-11-12 17:15:31,951 | root | INFO | Users\\'s init has completed successfully\\nUsers\\'s init has completed successfully\\n2020-11-12 17:15:31,953 | root | INFO | Skipping middleware: dbg_model_info as it\\'s not enabled.\\nSkipping middleware: dbg_model_info as it\\'s not enabled.\\n2020-11-12 17:15:31,953 | root | INFO | Skipping middleware: dbg_resource_usage as it\\'s not enabled.\\nSkipping middleware: dbg_resource_usage as it\\'s not enabled.\\n2020-11-12 17:15:31,953 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\\nScoring timeout setting is not found. Use default timeout: 3600000 ms\\n2020-11-12 17:15:59,190 | root | INFO | \\tHost: localhost:8890\\n\\tHost: localhost:8890\\n2020-11-12 17:15:59,190 | root | INFO | \\tX-Real-Ip: 172.17.0.1\\n\\tX-Real-Ip: 172.17.0.1\\n2020-11-12 17:15:59,190 | root | INFO | \\tX-Forwarded-For: 172.17.0.1\\n\\tX-Forwarded-For: 172.17.0.1\\n2020-11-12 17:15:59,191 | root | INFO | \\tX-Forwarded-Proto: http\\n\\tX-Forwarded-Proto: http\\n2020-11-12 17:15:59,191 | root | INFO | \\tConnection: close\\n\\tConnection: close\\n2020-11-12 17:15:59,191 | root | INFO | \\tContent-Length: 267927\\n\\tContent-Length: 267927\\n2020-11-12 17:15:59,191 | root | INFO | \\tCache-Control: no-cache\\n\\tCache-Control: no-cache\\n2020-11-12 17:15:59,191 | root | INFO | \\tPostman-Token: 74eefd43-e384-49cd-bf73-a67c7ac3b045\\n\\tPostman-Token: 74eefd43-e384-49cd-bf73-a67c7ac3b045\\n2020-11-12 17:15:59,191 | root | INFO | \\tContent-Type: text/plain\\n\\tContent-Type: text/plain\\n2020-11-12 17:15:59,191 | root | INFO | \\tUser-Agent: PostmanRuntime/7.6.0\\n\\tUser-Agent: PostmanRuntime/7.6.0\\n2020-11-12 17:15:59,191 | root | INFO | \\tAccept: */*\\n\\tAccept: */*\\n2020-11-12 17:15:59,191 | root | INFO | \\tAccept-Encoding: gzip, deflate\\n\\tAccept-Encoding: gzip, deflate\\n2020-11-12 17:15:59,191 | root | INFO | Scoring Timer is set to 3600.0 seconds\\nScoring Timer is set to 3600.0 seconds\\n[array([1.20575623e+03, 6.75729431e+02, 1.25083374e+03, 7.26230225e+02,\\n       8.58963370e-01, 0.00000000e+00]), array([1.35760828e+03, 9.80017639e+02, 1.39424939e+03, 1.01631763e+03,\\n       8.14378321e-01, 0.00000000e+00]), array([1.41927173e+03, 7.57038879e+02, 1.46116370e+03, 8.02347595e+02,\\n       6.89589918e-01, 0.00000000e+00]), array([  8.179245  , 389.76992798,  36.66374207, 428.94955444,\\n         0.65023148,   0.        ]), array([1.27165535e+02, 8.96088013e+02, 1.57287476e+02, 9.24766846e+02,\\n       6.00731552e-01, 0.00000000e+00]), array([1.37779016e+03, 5.61361023e+02, 1.41966248e+03, 6.09184509e+02,\\n       5.53165078e-01, 0.00000000e+00]), array([1.47185596e+03, 4.51053284e+02, 1.49625854e+03, 4.90898010e+02,\\n       5.24582028e-01, 0.00000000e+00]), array([8.34740677e+01, 7.20083069e+02, 1.25796875e+02, 7.63824341e+02,\\n       5.18618762e-01, 0.00000000e+00]), array([7.52371582e+02, 1.04525122e+03, 7.94527100e+02, 1.07900000e+03,\\n       4.85441595e-01, 0.00000000e+00]), array([1.78291736e+03, 3.50026459e+02, 1.81097925e+03, 3.95031372e+02,\\n       4.41002548e-01, 0.00000000e+00]), array([1.49143872e+03, 5.36391907e+02, 1.52127930e+03, 5.83640320e+02,\\n       3.94218028e-01, 0.00000000e+00]), array([1.32735437e+03, 4.80543030e+02, 1.36491272e+03, 5.23910889e+02,\\n       3.49622935e-01, 0.00000000e+00]), array([1.36936169e+03, 4.31443176e+02, 1.40834595e+03, 4.71430603e+02,\\n       3.42005253e-01, 0.00000000e+00]), array([1.26667793e+02, 8.62236206e+02, 2.01427673e+02, 9.28232178e+02,\\n       3.41030121e-01, 0.00000000e+00]), array([1.02360858e+03, 7.47462585e+02, 1.05474402e+03, 7.84200562e+02,\\n       3.27199519e-01, 0.00000000e+00]), array([7.42567932e+02, 9.99102295e+02, 8.02713196e+02, 1.07900000e+03,\\n       3.25881004e-01, 0.00000000e+00]), array([2.95346832e+02, 2.72042175e+02, 3.23250916e+02, 3.10836456e+02,\\n       3.06207120e-01, 0.00000000e+00]), array([1.20389648e+03, 6.47701721e+02, 1.24796655e+03, 7.02697998e+02,\\n       3.01908910e-01, 0.00000000e+00])]\\n2020-11-12 17:15:59,805 | root | ERROR | Encountered Exception: Traceback (most recent call last):\\n  File \"/var/azureml-server/app.py\", line 239, in run_scoring\\n    response = invoke_user_with_timer(service_input, request_headers)\\n  File \"/var/azureml-server/app.py\", line 309, in invoke_user_with_timer\\n    result = user_main.run(**params)\\n  File \"/var/azureml-app/yolo/score.py\", line 61, in run\\n    return AMLResponse(json.dumps(bboxes), 200)\\n  File \"/azureml-envs/azureml_431acb06527d440db41918b00defd142/lib/python3.6/json/__init__.py\", line 231, in dumps\\n    return _default_encoder.encode(obj)\\n  File \"/azureml-envs/azureml_431acb06527d440db41918b00defd142/lib/python3.6/json/encoder.py\", line 199, in encode\\n    chunks = self.iterencode(o, _one_shot=True)\\n  File \"/azureml-envs/azureml_431acb06527d440db41918b00defd142/lib/python3.6/json/encoder.py\", line 257, in iterencode\\n    return _iterencode(o, 0)\\n  File \"/azureml-envs/azureml_431acb06527d440db41918b00defd142/lib/python3.6/json/encoder.py\", line 180, in default\\n    o.__class__.__name__)\\nTypeError: Object of type \\'ndarray\\' is not JSON serializable\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/azureml-envs/azureml_431acb06527d440db41918b00defd142/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\\n    rv = self.dispatch_request()\\n  File \"/azureml-envs/azureml_431acb06527d440db41918b00defd142/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\\n    return self.view_functions[rule.endpoint](**req.view_args)\\n  File \"/var/azureml-server/app.py\", line 142, in score_realtime\\n    return run_scoring(service_input, request.headers, request.environ.get(\\'REQUEST_ID\\', \\'00000000-0000-0000-0000-000000000000\\'))\\n  File \"/var/azureml-server/app.py\", line 252, in run_scoring\\n    raise RunFunctionException(str(exc))\\nrun_function_exception.RunFunctionException\\n\\nEncountered Exception: Traceback (most recent call last):\\n  File \"/var/azureml-server/app.py\", line 239, in run_scoring\\n    response = invoke_user_with_timer(service_input, request_headers)\\n  File \"/var/azureml-server/app.py\", line 309, in invoke_user_with_timer\\n    result = user_main.run(**params)\\n  File \"/var/azureml-app/yolo/score.py\", line 61, in run\\n    return AMLResponse(json.dumps(bboxes), 200)\\n  File \"/azureml-envs/azureml_431acb06527d440db41918b00defd142/lib/python3.6/json/__init__.py\", line 231, in dumps\\n    return _default_encoder.encode(obj)\\n  File \"/azureml-envs/azureml_431acb06527d440db41918b00defd142/lib/python3.6/json/encoder.py\", line 199, in encode\\n    chunks = self.iterencode(o, _one_shot=True)\\n  File \"/azureml-envs/azureml_431acb06527d440db41918b00defd142/lib/python3.6/json/encoder.py\", line 257, in iterencode\\n    return _iterencode(o, 0)\\n  File \"/azureml-envs/azureml_431acb06527d440db41918b00defd142/lib/python3.6/json/encoder.py\", line 180, in default\\n    o.__class__.__name__)\\nTypeError: Object of type \\'ndarray\\' is not JSON serializable\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/azureml-envs/azureml_431acb06527d440db41918b00defd142/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\\n    rv = self.dispatch_request()\\n  File \"/azureml-envs/azureml_431acb06527d440db41918b00defd142/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\\n    return self.view_functions[rule.endpoint](**req.view_args)\\n  File \"/var/azureml-server/app.py\", line 142, in score_realtime\\n    return run_scoring(service_input, request.headers, request.environ.get(\\'REQUEST_ID\\', \\'00000000-0000-0000-0000-000000000000\\'))\\n  File \"/var/azureml-server/app.py\", line 252, in run_scoring\\n    raise RunFunctionException(str(exc))\\nrun_function_exception.RunFunctionException\\n\\n2020-11-12 17:15:59,805 | root | INFO | 500\\n500\\n127.0.0.1 - - [12/Nov/2020:17:15:59 +0000] \"POST /score HTTP/1.0\" 500 49 \"-\" \"PostmanRuntime/7.6.0\"\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service.get_logs(num_lines=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container has been successfully cleaned up.\n"
     ]
    }
   ],
   "source": [
    "service.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toc_azureml",
   "language": "python",
   "name": "toc_azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
