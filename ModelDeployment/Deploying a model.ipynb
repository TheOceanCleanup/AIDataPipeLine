{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How-to deploy a model on Azure ML\n",
    "\n",
    "This notebook takes you through the steps of deploying a model on Azure for The Ocean Cleanup. We can deploy any model registered after the training as seen in the notebooks of the `ModelTraining` directory.\n",
    "\n",
    "Next to the concepts introduced in those notebooks, there are a few additional concepts we need to know about:\n",
    "\n",
    "- score script: A Python script that contains the code of how to perform inference. Implements two functions:\n",
    "  - `init()`: Initializing function run once when the container is started. Initialize your model here\n",
    "  - `run(request)`: Function that is called for every request to the endpoint. This endpoint is called with the\n",
    "    binary image data as body, which is provided to the function through request.get_data(). The response is\n",
    "    sent back.\n",
    "- Service: A deployed model. This provides an `endpoint` to which we can send data.\n",
    "- Endpoint: This is provided by a service. Is an URI to which inference requests can be sent.\n",
    "- InferenceConfig: Configuration describing how the inference should be performed. This contains the score script,\n",
    "  the source it is run in and the environment it should use.\n",
    "- DeployConfig: The configuration of where to deploy the service. This can be a LocalWebservice, AciWebservice or\n",
    "  AksWebservice. The former 2 are aimed at development work, the later for production.\n",
    "- Compute Target: When using an AksWebservice, the Compute Target must be named. This is the AKS cluster where to\n",
    "  run the service. This should be registered as 'Inference cluster' in Azure ML.\n",
    "  \n",
    "Before we get to work with these, we need to load in our workspace again, like before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azurewrapper.workspace import get_workspace\n",
    "\n",
    "subscription_id = \"29d66431-a7ce-4709-93f7-3bdb01a243b3\"\n",
    "resource_group = \"ExperimentationJayke\"\n",
    "workspace_name = \"ExperimentationJayke\"\n",
    "\n",
    "workspace = get_workspace(subscription_id, resource_group, workspace_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, like before, we need to create or load an environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No environment with that name found, creating new one\n"
     ]
    }
   ],
   "source": [
    "from azurewrapper.environment import get_environment\n",
    "\n",
    "environment = get_environment(\n",
    "    workspace,\n",
    "    \"example_model_env\",\n",
    "    pip_requirements=\"./examples/example_model/requirements.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to load the model. Note that it is possible to provide multiple models to the Service. However, in the current architectural design, we deploy a single model as a single service, and therefore single endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "model = Model(workspace, \"example_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this time, the score script should be implemented. The score script implements an `init()` function, and a `run(request)` function. Note that we will deploy the entire folder containing the `score.py` script, so it is perfectly fine to use imports within that and spread your code over multiple files.\n",
    "\n",
    "The provided model is used as follows: The artifacts stored with the model will be loaded into a folder, that is pointed to by the environment variable `AZUREML_MODEL_DIR`. When multiple models are provided, there will be an extra layer of subdirectories there, where each folder has the name of a model used. The artifacts will then be inside that folder.\n",
    "\n",
    "The folder structure is kept the same as shown in the `Artifacts` tab of the Azure ML Studio interface for a model.\n",
    "\n",
    "## Deploying the model\n",
    "\n",
    "Once we have the score script ready, it's time to deploy the model. The function `azurewrapper.deploy.deploy()` can help with this. It will create the correct InferenceConfig and DeployConfig, and will use those to create the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running......\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azurewrapper.deploy import deploy\n",
    "service = deploy(\n",
    "    workspace,\n",
    "    \"testdeploy\",\n",
    "    model,\n",
    "    \"score.py\",\n",
    "    \"examples/example_model\",\n",
    "    environment=environment,\n",
    "    target='aks',\n",
    "    compute_target_name='deploy-test'\n",
    ")\n",
    "service.wait_for_deployment(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the service is created, we can determine the scoring uri. This (naturally) depends on the type of service that was created. The following possible endpoints will be created:\n",
    "- LocalWebservice: `http://localhost:8890/score` (port is defined in `azurewrapper.deploy.deploy()`\n",
    "- AciWebservice: `http://<some uuid>.<region>.azurecontainer.io/score`,\n",
    "  eg `http://5222e98a-6791-4ed8-a4c6-c44e36b0c9cb.westeurope.azurecontainer.io/score`\n",
    "- AksWebservice: `http://<cluster IP>/api/v1/service/<service name>/score`,\n",
    "  eg. `http://20.71.137.87:80/api/v1/service/testdeploy/score`\n",
    "    \n",
    "Other interesting endpoints may be the same url without `/score` (eg `http://20.71.137.87:80/api/v1/service/testdeploy`, this provides a health check, and `http://20.71.137.87:80/api/v1/service/testdeploy/ui` for a Swagger interface of the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://13.95.2.180:80/api/v1/service/testdeploy/score'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service.scoring_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-11-11T15:10:20,532805734+00:00 - rsyslog/run \\n2020-11-11T15:10:20,533104136+00:00 - iot-server/run \\n/usr/sbin/nginx: /azureml-envs/azureml_6cfb08ae90424295b381c464fea452e2/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_6cfb08ae90424295b381c464fea452e2/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_6cfb08ae90424295b381c464fea452e2/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_6cfb08ae90424295b381c464fea452e2/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_6cfb08ae90424295b381c464fea452e2/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n2020-11-11T15:10:20,535227350+00:00 - nginx/run \\n2020-11-11T15:10:20,537662666+00:00 - gunicorn/run \\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\n2020-11-11T15:10:20,606893128+00:00 - iot-server/finish 1 0\\n2020-11-11T15:10:20,608042636+00:00 - Exit code 1 is normal. Not restarting iot-server.\\nStarting gunicorn 19.9.0\\nListening at: http://127.0.0.1:31311 (11)\\nUsing worker: sync\\nworker timeout is set to 300\\nBooting worker with pid: 41\\nSPARK_HOME not set. Skipping PySpark Initialization.\\nInitializing logger\\n2020-11-11 15:10:20,924 | root | INFO | Starting up app insights client\\nStarting up app insights client\\n2020-11-11 15:10:20,924 | root | INFO | Starting up request id generator\\nStarting up request id generator\\n2020-11-11 15:10:20,925 | root | INFO | Starting up app insight hooks\\nStarting up app insight hooks\\n2020-11-11 15:10:20,925 | root | INFO | Invoking user\\'s init function\\nInvoking user\\'s init function\\n2020-11-11 15:10:20,925 | root | INFO | Users\\'s init has completed successfully\\nUsers\\'s init has completed successfully\\n2020-11-11 15:10:20,927 | root | INFO | Skipping middleware: dbg_model_info as it\\'s not enabled.\\nSkipping middleware: dbg_model_info as it\\'s not enabled.\\n2020-11-11 15:10:20,927 | root | INFO | Skipping middleware: dbg_resource_usage as it\\'s not enabled.\\nSkipping middleware: dbg_resource_usage as it\\'s not enabled.\\n2020-11-11 15:10:20,928 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\\nScoring timeout setting is not found. Use default timeout: 3600000 ms\\n2020-11-11 15:10:27,137 | root | INFO | Swagger file not present\\nSwagger file not present\\n2020-11-11 15:10:27,138 | root | INFO | 404\\n404\\n127.0.0.1 - - [11/Nov/2020:15:10:27 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"-\"\\n2020-11-11 15:10:27,401 | root | INFO | Swagger file not present\\nSwagger file not present\\n2020-11-11 15:10:27,401 | root | INFO | 404\\n404\\n127.0.0.1 - - [11/Nov/2020:15:10:27 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"curl/7.67.0\"\\n2020-11-11 15:10:31,961 | root | INFO | Swagger file not present\\nSwagger file not present\\n2020-11-11 15:10:31,961 | root | INFO | 404\\n404\\n127.0.0.1 - - [11/Nov/2020:15:10:31 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"-\"\\n2020-11-11 15:10:38,753 | root | INFO | Swagger file not present\\nSwagger file not present\\n2020-11-11 15:10:38,754 | root | INFO | 404\\n404\\n127.0.0.1 - - [11/Nov/2020:15:10:38 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"curl/7.67.0\"\\n2020-11-11 15:13:15,893 | root | INFO | \\tHost: 13.95.2.180:80\\n\\tHost: 13.95.2.180:80\\n2020-11-11 15:13:15,893 | root | INFO | \\tX-Real-Ip: 10.244.0.11\\n\\tX-Real-Ip: 10.244.0.11\\n2020-11-11 15:13:15,893 | root | INFO | \\tX-Forwarded-For: 10.244.0.11\\n\\tX-Forwarded-For: 10.244.0.11\\n2020-11-11 15:13:15,893 | root | INFO | \\tX-Forwarded-Proto: http\\n\\tX-Forwarded-Proto: http\\n2020-11-11 15:13:15,893 | root | INFO | \\tConnection: close\\n\\tConnection: close\\n2020-11-11 15:13:15,893 | root | INFO | \\tContent-Length: 38736\\n\\tContent-Length: 38736\\n2020-11-11 15:13:15,893 | root | INFO | \\tUser-Agent: PostmanRuntime/7.6.0\\n\\tUser-Agent: PostmanRuntime/7.6.0\\n2020-11-11 15:13:15,893 | root | INFO | \\tPostman-Token: 30808e19-4f4b-4c7d-9c58-5a0b49417c08\\n\\tPostman-Token: 30808e19-4f4b-4c7d-9c58-5a0b49417c08\\n2020-11-11 15:13:15,893 | root | INFO | \\tContent-Type: application/json\\n\\tContent-Type: application/json\\n2020-11-11 15:13:15,893 | root | INFO | \\tCache-Control: no-cache\\n\\tCache-Control: no-cache\\n2020-11-11 15:13:15,893 | root | INFO | \\tAccept-Encoding: gzip, deflate\\n\\tAccept-Encoding: gzip, deflate\\n2020-11-11 15:13:15,894 | root | INFO | \\tAccept: */*\\n\\tAccept: */*\\n2020-11-11 15:13:15,894 | root | INFO | \\tX-Ms-Request-Id: 5b801eb6-dcb2-429b-8a9e-9f16eba0d2db\\n\\tX-Ms-Request-Id: 5b801eb6-dcb2-429b-8a9e-9f16eba0d2db\\n2020-11-11 15:13:15,894 | root | INFO | Scoring Timer is set to 3600.0 seconds\\nScoring Timer is set to 3600.0 seconds\\n2020-11-11 15:13:15,894 | root | INFO | run() output is HTTP Response\\nrun() output is HTTP Response\\n2020-11-11 15:13:15,894 | root | INFO | 200\\n200\\n127.0.0.1 - - [11/Nov/2020:15:13:15 +0000] \"POST /score HTTP/1.0\" 200 1 \"-\" \"PostmanRuntime/7.6.0\"\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toc_azureml",
   "language": "python",
   "name": "toc_azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
