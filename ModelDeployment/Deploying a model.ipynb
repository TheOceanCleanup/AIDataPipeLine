{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How-to deploy a model on Azure ML\n",
    "\n",
    "This notebook takes you through the steps of deploying a model on Azure for The Ocean Cleanup. We can deploy any model registered after the training as seen in the notebooks of the `ModelTraining` directory.\n",
    "\n",
    "Next to the concepts introduced in those notebooks, there are a few additional concepts we need to know about:\n",
    "\n",
    "- score script: A Python script that contains the code of how to perform inference. Implements two functions:\n",
    "  - `init()`: Initializing function run once when the container is started. Initialize your model here\n",
    "  - `run(request)`: Function that is called for every request to the endpoint. This endpoint is called with the\n",
    "    binary image data as body, which is provided to the function through request.get_data(). The response is\n",
    "    sent back.\n",
    "- Service: A deployed model. This provides an `endpoint` to which we can send data.\n",
    "- Endpoint: This is provided by a service. Is an URI to which inference requests can be sent.\n",
    "- InferenceConfig: Configuration describing how the inference should be performed. This contains the score script,\n",
    "  the source it is run in and the environment it should use.\n",
    "- DeployConfig: The configuration of where to deploy the service. This can be a LocalWebservice, AciWebservice or\n",
    "  AksWebservice. The former 2 are aimed at development work, the later for production.\n",
    "- Compute Target: When using an AksWebservice, the Compute Target must be named. This is the AKS cluster where to\n",
    "  run the service. This should be registered as 'Inference cluster' in Azure ML.\n",
    "  \n",
    "Before we get to work with these, we need to load in our workspace again, like before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azurewrapper.workspace import get_workspace\n",
    "\n",
    "subscription_id = \"a00eaec6-b320-4e7c-ae61-60a30aec1cfc\"\n",
    "resource_group = \"MachineLearning\"\n",
    "workspace_name = \"RiverImageAnalysis\"\n",
    "tenant_id = \"86f9fea7-9eb0-4325-8b58-7ed0db623956\"\n",
    "\n",
    "workspace = get_workspace(subscription_id, resource_group, workspace_name, tenant_id=tenant_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, like before, we need to create or load an environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No environment with that name found, creating new one\n"
     ]
    }
   ],
   "source": [
    "from azurewrapper.environment import get_environment\n",
    "\n",
    "environment = get_environment(\n",
    "    workspace,\n",
    "    \"example_model_env\",\n",
    "    pip_requirements=\"./examples/example_model/requirements.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to load the model. Note that it is possible to provide multiple models to the Service. However, in the current architectural design, we deploy a single model as a single service, and therefore single endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "model = Model(workspace, \"example_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this time, the score script should be implemented. The score script implements an `init()` function, and a `run(request)` function. Note that we will deploy the entire folder containing the `score.py` script, so it is perfectly fine to use imports within that and spread your code over multiple files.\n",
    "\n",
    "The provided model is used as follows: The artifacts stored with the model will be loaded into a folder, that is pointed to by the environment variable `AZUREML_MODEL_DIR`. When multiple models are provided, there will be an extra layer of subdirectories there, where each folder has the name of a model used. The artifacts will then be inside that folder.\n",
    "\n",
    "The folder structure is kept the same as shown in the `Artifacts` tab of the Azure ML Studio interface for a model.\n",
    "\n",
    "## Deploying the model\n",
    "\n",
    "Once we have the score script ready, it's time to deploy the model. The function `azurewrapper.deploy.deploy()` can help with this. It will create the correct InferenceConfig and DeployConfig, and will use those to create the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running......\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azurewrapper.deploy import deploy\n",
    "service = deploy(\n",
    "    workspace,\n",
    "    \"testdeploy\",\n",
    "    model,\n",
    "    \"score.py\",\n",
    "    \"examples/example_model\",\n",
    "    environment=environment,\n",
    "    target='aks',\n",
    "    compute_target_name='deploy-test'\n",
    ")\n",
    "service.wait_for_deployment(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the service is created, we can determine the scoring uri. This (naturally) depends on the type of service that was created. The following possible endpoints will be created:\n",
    "- LocalWebservice: `http://localhost:8890/score` (port is defined in `azurewrapper.deploy.deploy()`\n",
    "- AciWebservice: `http://<some uuid>.<region>.azurecontainer.io/score`,\n",
    "  eg `http://5222e98a-6791-4ed8-a4c6-c44e36b0c9cb.westeurope.azurecontainer.io/score`\n",
    "- AksWebservice: `http://<cluster IP>/api/v1/service/<service name>/score`,\n",
    "  eg. `http://20.71.137.87:80/api/v1/service/testdeploy/score`\n",
    "    \n",
    "Other interesting endpoints may be the same url without `/score` (eg `http://20.71.137.87:80/api/v1/service/testdeploy`, this provides a health check, and `http://20.71.137.87:80/api/v1/service/testdeploy/ui` for a Swagger interface of the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://13.95.2.180:80/api/v1/service/testdeploy/score'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service.scoring_uri"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toc_azureml",
   "language": "python",
   "name": "toc_azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
