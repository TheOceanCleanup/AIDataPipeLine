{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How-to train a model on Azure ML\n",
    "\n",
    "This notebook takes you through the steps of training a model on Azure ML for The Ocean Cleanup. We train the models through Azure ML to provide us with a good registration of all performed tests, so that we can see why and how a model was created.\n",
    "\n",
    "When the result of a training run is satisfactory, a model can be registered from there, from which point we can deploy it.\n",
    "\n",
    "There are a few concepts to know about first:\n",
    "\n",
    "- Workspace: The entire AzureML environment you are working in. The Workspace contains all the other elements.\n",
    "- Experiment: A collection of Runs (see below). A logical container for training a model with different parameters to determine the best.\n",
    "- Run: A single train/test run of a model. These are tied to an experiment. If you want to train the same model with different parameters, so you can compare them, these are different runs under the same experiment.\n",
    "- Environment: The code environment used by your code. This contains things like the required Python packages. Multiple options exist here - from just using your local environment to completely curated environments directly from Azure.\n",
    "- Dataset: A single dataset as registered in the AzureML workspace.\n",
    "\n",
    "With that out of the way, lets dive right in. Looking at these components, our first step will be to get the correct Workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azurewrapper.workspace import get_workspace\n",
    "\n",
    "subscription_id = \"29d66431-a7ce-4709-93f7-3bdb01a243b3\"\n",
    "resource_group = \"ExperimentationJayke\"\n",
    "workspace_name = \"ExperimentationJayke\"\n",
    "\n",
    "workspace = get_workspace(subscription_id, resource_group, workspace_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create experiment\n",
    "\n",
    "Now that we have a workspace available, we need to create an experiment. As describe above, an experiment will be the container for multiple runs, in which we can train and compare the model using different parameters.\n",
    "\n",
    "The experiment needs a name. Use something that is descriptive and clear to anyone seeing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azurewrapper.train import create_experiment\n",
    "experiment = create_experiment(workspace, \"model-frcnn-v-1-0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or select compute target\n",
    "\n",
    "We want to train our model on a GPU cluster on AzureML. Lets create one (or load an existing one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target\n"
     ]
    }
   ],
   "source": [
    "from azurewrapper.compute import get_compute\n",
    "\n",
    "compute_target = get_compute(workspace, \"gpu-cluster\", vm_size='STANDARD_NC6', max_nodes=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the environment\n",
    "\n",
    "We will now need to create an environment. In this case, we build our own from a Docker file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azurewrapper.environment import get_environment\n",
    "\n",
    "\n",
    "environment = Environment(\"custom_tensorflow_object_detection\")\n",
    "environment.docker.enabled = True\n",
    "\n",
    "# Load from dockerfile\n",
    "environment.docker.base_image = None\n",
    "environment.docker.base_dockerfile = \"./examples/frcnn/Dockerfile\"\n",
    "environment.python.user_managed_dependencies = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model wraper\n",
    "\n",
    "Now it's time to perform our first Run of the experiment. However, before we can do this, we will need a wrapper around our model. This wrapper needs to do a few things:\n",
    "\n",
    "- Initialize and train the model with:\n",
    "  - The desired parameters\n",
    "  - The desired data\n",
    "- Evaluate the performance of the trained model\n",
    "- Register the parameters and the performance in the Run object\n",
    "- Add the generated model artifacts to the Run object\n",
    "\n",
    "There is skeleton code for this available: `skeleton_files/train.py`. In this file you fill in what parameters you expect, you create and train and evaluate the model using these parameters and the loaded in dataset(s), and you register the results and the created artifacts with the Run.\n",
    "\n",
    "For this how-to, we will use the example provided in `examples/frcnn/train.py`. This is an implementation of the file mentioned above. It expects two parameters: `num_train_steps` and `sample_1_of_n_eval_examples`.\n",
    "\n",
    "## Run the experiment\n",
    "\n",
    "Now we need to create and run the experiment. First, we fetch the desired datasets, and combine these into train- and test sets. Note that we can provide multiple sets for both training and testing. Also note that each set consists of both a label and an image dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "train_images = Dataset.get_by_name(workspace, name=\"campaign-26-10-2020_images\")\n",
    "train_labels = Dataset.get_by_name(workspace, name=\"campaign-26-10-2020_labels\")\n",
    "test_images = Dataset.get_by_name(workspace, name=\"campaign-22-10-2020_images\")\n",
    "test_labels = Dataset.get_by_name(workspace, name=\"campaign-22-10-2020_labels\")\n",
    "trainsets = [\n",
    "    (train_labels, train_images),\n",
    "    (test_labels, test_images)\n",
    "]\n",
    "testsets = [\n",
    "    (test_labels, test_images)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have everything we need to perform the run locally. Lets do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: model-frcnn-v-1-0_1604571475_b972cb37\n",
      "Web View: https://ml.azure.com/experiments/model-frcnn-v-1-0/runs/model-frcnn-v-1-0_1604571475_b972cb37?wsid=/subscriptions/29d66431-a7ce-4709-93f7-3bdb01a243b3/resourcegroups/ExperimentationJayke/workspaces/ExperimentationJayke\n"
     ]
    },
    {
     "ename": "ExperimentExecutionException",
     "evalue": "ExperimentExecutionException:\n\tMessage: The output streaming for the run interrupted.\nBut the run is still executing on the compute target. \nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"The output streaming for the run interrupted.\\nBut the run is still executing on the compute target. \\nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.virtualenvs/toc_azureml/lib/python3.6/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m    715\u001b[0m                     \u001b[0mwait_post_processing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait_post_processing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m                     raise_on_error=raise_on_error)\n\u001b[0m\u001b[1;32m    717\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/toc_azureml/lib/python3.6/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[0;34m(self, file_handle, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0mfile_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_before_polling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpoll_start_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_details\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# TODO use FileWatcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mExperimentExecutionException\u001b[0m              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4e330e6764c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                       \u001b[0;34m'checkpoint_dataset'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcheckpoint_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_named_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'checkpoint'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_mount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                   })\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/toc_azureml/lib/python3.6/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m    722\u001b[0m                                 \u001b[0;34m\"https://aka.ms/aml-docs-cancel-run\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mExperimentExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0mrunning_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRUNNING_STATES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mExperimentExecutionException\u001b[0m: ExperimentExecutionException:\n\tMessage: The output streaming for the run interrupted.\nBut the run is still executing on the compute target. \nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"The output streaming for the run interrupted.\\nBut the run is still executing on the compute target. \\nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "from azurewrapper.train import perform_run\n",
    "from azureml.core.runconfig import TensorflowConfiguration\n",
    "\n",
    "checkpoint_files = Dataset.get_by_name(workspace, name=\"FRCNN\")\n",
    "\n",
    "# perform_run(experiment, script, source_directory, environment=None,\n",
    "#             compute_target=None, datasets=[], parameters={})\n",
    "# run = perform_run(experiment, 'train.py', 'examples/example_model', environment=environment,\n",
    "#                   datasets=datasets, parameters={'param_a': 30, 'param_b': 12.0})\n",
    "run = perform_run(experiment, 'train.py', 'examples/frcnn', environment=environment,\n",
    "                  trainsets=trainsets, testsets=testsets, compute_target=compute_target,\n",
    "                  parameters={\n",
    "                      'num_train_steps': 10000,\n",
    "                      'sample_1_of_n_eval_examples': 1,\n",
    "                      'checkpoint_dataset': checkpoint_files.as_named_input(f'checkpoint').as_mount()\n",
    "                  })\n",
    "run.wait_for_completion(show_output=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toc_azureml",
   "language": "python",
   "name": "toc_azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
