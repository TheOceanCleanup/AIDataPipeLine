{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How-to train a model on Azure ML\n",
    "\n",
    "This notebook takes you through the steps of training a model on Azure ML for The Ocean Cleanup. We train the models through Azure ML to provide us with a good registration of all performed tests, so that we can see why and how a model was created.\n",
    "\n",
    "When the result of a training run is satisfactory, a model can be registered from there, from which point we can deploy it.\n",
    "\n",
    "There are a few concepts to know about first:\n",
    "\n",
    "- Workspace: The entire AzureML environment you are working in. The Workspace contains all the other elements.\n",
    "- Experiment: A collection of Runs (see below). A logical container for training a model with different parameters to determine the best.\n",
    "- Run: A single train/test run of a model. These are tied to an experiment. If you want to train the same model with different parameters, so you can compare them, these are different runs under the same experiment.\n",
    "- Environment: The code environment used by your code. This contains things like the required Python packages. Multiple options exist here - from just using your local environment to completely curated environments directly from Azure.\n",
    "- Dataset: A single dataset as registered in the AzureML workspace.\n",
    "\n",
    "With that out of the way, lets dive right in. Looking at these components, our first step will be to get the correct Workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azurewrapper.workspace import get_workspace\n",
    "\n",
    "subscription_id = \"29d66431-a7ce-4709-93f7-3bdb01a243b3\"\n",
    "resource_group = \"ExperimentationJayke\"\n",
    "workspace_name = \"ExperimentationJayke\"\n",
    "\n",
    "workspace = get_workspace(subscription_id, resource_group, workspace_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create experiment\n",
    "\n",
    "Now that we have a workspace available, we need to create an experiment. As describe above, an experiment will be the container for multiple runs, in which we can train and compare the model using different parameters.\n",
    "\n",
    "The experiment needs a name. Use something that is descriptive and clear to anyone seeing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azurewrapper.train import create_experiment\n",
    "experiment = create_experiment(workspace, \"model-yolov5-v-1-0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or select compute target\n",
    "\n",
    "We want to train our model on a GPU cluster on AzureML. Lets create one (or load an existing one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target\n"
     ]
    }
   ],
   "source": [
    "from azurewrapper.compute import get_compute\n",
    "\n",
    "compute_target = get_compute(workspace, \"gpu-cluster\", vm_size='STANDARD_NC6', max_nodes=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the environment\n",
    "\n",
    "We will now need to create an environment. In this case, we build the enviroment based of the Azure docker Tensorflow image, but with our own pip requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azurewrapper.environment import get_environment\n",
    "\n",
    "\n",
    "#environment = get_environment(workspace, 'AzureML-TensorFlow-2.2-GPU')\n",
    "#environment.save_to_directory(path='deps.yml')\n",
    "environment = Environment.from_pip_requirements(name=\"pytorch-exp\", file_path=\"./examples/yolov5/yolov5/requirements.txt\")\n",
    "environment.docker.enabled = True\n",
    "environment.docker.base_image = \"mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04:20201019.v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model wraper\n",
    "\n",
    "Now it's time to perform our first Run of the experiment. However, before we can do this, we will need a wrapper around our model. This wrapper needs to do a few things:\n",
    "\n",
    "- Initialize and train the model with:\n",
    "  - The desired parameters\n",
    "  - The desired data\n",
    "- Evaluate the performance of the trained model\n",
    "- Register the parameters and the performance in the Run object\n",
    "- Add the generated model artifacts to the Run object\n",
    "\n",
    "There is skeleton code for this available: `skeleton_files/train.py`. In this file you fill in what parameters you expect, you create and train and evaluate the model using these parameters and the loaded in dataset(s), and you register the results and the created artifacts with the Run.\n",
    "\n",
    "For this how-to, we will use the example provided in `examples/yolov5/train.py`. This is an implementation of the file mentioned above. It accepts x parameters: `LR_INIT`, `LR_END`, `WARMUP_EPOCHS` and `EPOCHS`, and requires `yolov5 weights` as dataset.\n",
    "\n",
    "### Changes to yolo code\n",
    "\n",
    "- Added AzureML files to `yolov5/requirements.txt`\n",
    "\n",
    "## Run the experiment\n",
    "\n",
    "Now we need to create and run the experiment. First, we fetch the desired datasets, and combine these into train- and test sets. Note that we can provide multiple sets for both training and testing. Also note that each set consists of both a label and an image dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "train_images = Dataset.get_by_name(workspace, name=\"campaign-26-10-2020_images\")\n",
    "train_labels = Dataset.get_by_name(workspace, name=\"campaign-26-10-2020_labels\")\n",
    "test_images = Dataset.get_by_name(workspace, name=\"campaign-22-10-2020_images\")\n",
    "test_labels = Dataset.get_by_name(workspace, name=\"campaign-22-10-2020_labels\")\n",
    "trainsets = [\n",
    "    (train_labels, train_images),\n",
    "    (test_labels, test_images)\n",
    "]\n",
    "testsets = [\n",
    "    (test_labels, test_images)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have everything we need to perform the run. Lets do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: model-yolov5-v-1-0_1604506223_8242fcca\n",
      "Web View: https://ml.azure.com/experiments/model-yolov5-v-1-0/runs/model-yolov5-v-1-0_1604506223_8242fcca?wsid=/subscriptions/29d66431-a7ce-4709-93f7-3bdb01a243b3/resourcegroups/ExperimentationJayke/workspaces/ExperimentationJayke\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_0c3513d5d2fe1997bd3d6439f214dc9dd814320a9df8761f283975506cbf87f6_d.txt\n",
      "========================================================================================================================\n",
      "\n",
      "2020-11-04T16:17:13Z Starting output-watcher...\n",
      "2020-11-04T16:17:13Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2020-11-04T16:17:15Z Executing 'Copy ACR Details file' on 10.0.0.5\n",
      "2020-11-04T16:17:15Z Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_4521102f55c0afd31b15be7f37fe801b\n",
      "171857c49d0f: Pulling fs layer\n",
      "419640447d26: Pulling fs layer\n",
      "61e52f862619: Pulling fs layer\n",
      "c118dad7e37a: Pulling fs layer\n",
      "2e36372995f9: Pulling fs layer\n",
      "0b8e00a4ba4e: Pulling fs layer\n",
      "b3026b4f2581: Pulling fs layer\n",
      "93cc193ccd98: Pulling fs layer\n",
      "ee06e59a4314: Pulling fs layer\n",
      "b0ac690bb2f2: Pulling fs layer\n",
      "5f11ace0944e: Pulling fs layer\n",
      "d4e18c29e104: Pulling fs layer\n",
      "09ba06861fca: Pulling fs layer\n",
      "c118dad7e37a: Waiting\n",
      "93cc193ccd98: Waiting\n",
      "ee06e59a4314: Waiting\n",
      "2e36372995f9: Waiting\n",
      "83213e0b5131: Pulling fs layer\n",
      "b0ac690bb2f2: Waiting\n",
      "0b8e00a4ba4e: Waiting\n",
      "7b0feb8d64db: Pulling fs layer\n",
      "7b0b507bb1e9: Pulling fs layer\n",
      "94e0f0e2d7da: Pulling fs layer\n",
      "5f11ace0944e: Waiting\n",
      "45b4bc5400c1: Pulling fs layer\n",
      "83213e0b5131: Waiting\n",
      "d4e18c29e104: Waiting\n",
      "30f9a1497794: Pulling fs layer\n",
      "a268272cc5cc: Pulling fs layer\n",
      "f14a9b32cda2: Pulling fs layer\n",
      "e0b4889704d9: Pulling fs layer\n",
      "8a5cda015470: Pulling fs layer\n",
      "b3026b4f2581: Waiting\n",
      "7b0feb8d64db: Waiting\n",
      "7b0b507bb1e9: Waiting\n",
      "94e0f0e2d7da: Waiting\n",
      "a268272cc5cc: Waiting\n",
      "f14a9b32cda2: Waiting\n",
      "30f9a1497794: Waiting\n",
      "4a02639176db: Pulling fs layer\n",
      "209dc1f1bb30: Pulling fs layer\n",
      "45b4bc5400c1: Waiting\n",
      "8a5cda015470: Waiting\n",
      "e0b4889704d9: Waiting\n",
      "209dc1f1bb30: Waiting\n",
      "09ba06861fca: Waiting\n",
      "61e52f862619: Verifying Checksum\n",
      "61e52f862619: Download complete\n",
      "419640447d26: Verifying Checksum\n",
      "419640447d26: Download complete\n",
      "c118dad7e37a: Verifying Checksum\n",
      "c118dad7e37a: Download complete\n",
      "2e36372995f9: Verifying Checksum\n",
      "2e36372995f9: Download complete\n",
      "171857c49d0f: Verifying Checksum\n",
      "171857c49d0f: Download complete\n",
      "0b8e00a4ba4e: Verifying Checksum\n",
      "0b8e00a4ba4e: Download complete\n",
      "93cc193ccd98: Verifying Checksum\n",
      "93cc193ccd98: Download complete\n",
      "b0ac690bb2f2: Verifying Checksum\n",
      "b0ac690bb2f2: Download complete\n",
      "171857c49d0f: Pull complete\n",
      "419640447d26: Pull complete\n",
      "61e52f862619: Pull complete\n",
      "c118dad7e37a: Pull complete\n",
      "2e36372995f9: Pull complete\n",
      "0b8e00a4ba4e: Pull complete\n",
      "5f11ace0944e: Verifying Checksum\n",
      "5f11ace0944e: Download complete\n",
      "b3026b4f2581: Verifying Checksum\n",
      "b3026b4f2581: Download complete\n",
      "d4e18c29e104: Verifying Checksum\n",
      "d4e18c29e104: Download complete\n",
      "09ba06861fca: Verifying Checksum\n",
      "09ba06861fca: Download complete\n",
      "83213e0b5131: Verifying Checksum\n",
      "83213e0b5131: Download complete\n",
      "7b0b507bb1e9: Verifying Checksum\n",
      "7b0b507bb1e9: Download complete\n",
      "7b0feb8d64db: Verifying Checksum\n",
      "7b0feb8d64db: Download complete\n",
      "94e0f0e2d7da: Verifying Checksum\n",
      "94e0f0e2d7da: Download complete\n",
      "30f9a1497794: Verifying Checksum\n",
      "30f9a1497794: Download complete\n",
      "45b4bc5400c1: Verifying Checksum\n",
      "45b4bc5400c1: Download complete\n",
      "a268272cc5cc: Verifying Checksum\n",
      "a268272cc5cc: Download complete\n",
      "f14a9b32cda2: Verifying Checksum\n",
      "f14a9b32cda2: Download complete\n",
      "e0b4889704d9: Verifying Checksum\n",
      "8a5cda015470: Verifying Checksum\n",
      "8a5cda015470: Download complete\n",
      "209dc1f1bb30: Verifying Checksum\n",
      "209dc1f1bb30: Download complete\n",
      "ee06e59a4314: Verifying Checksum\n",
      "ee06e59a4314: Download complete\n",
      "4a02639176db: Verifying Checksum\n",
      "4a02639176db: Download complete\n",
      "b3026b4f2581: Pull complete\n",
      "93cc193ccd98: Pull complete\n",
      "ee06e59a4314: Pull complete\n",
      "b0ac690bb2f2: Pull complete\n",
      "5f11ace0944e: Pull complete\n",
      "d4e18c29e104: Pull complete\n",
      "09ba06861fca: Pull complete\n",
      "83213e0b5131: Pull complete\n",
      "7b0feb8d64db: Pull complete\n",
      "7b0b507bb1e9: Pull complete\n",
      "94e0f0e2d7da: Pull complete\n",
      "45b4bc5400c1: Pull complete\n",
      "30f9a1497794: Pull complete\n",
      "a268272cc5cc: Pull complete\n",
      "f14a9b32cda2: Pull complete\n",
      "e0b4889704d9: Pull complete\n",
      "8a5cda015470: Pull complete\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "2020/11/04 16:19:41 logger.go:297: Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/info\n",
      "2020/11/04 16:19:41 logger.go:297: Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n",
      "[2020-11-04T16:19:42.589849] Entering context manager injector.\n",
      "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['train.py', '--train_sets', '0046c288-9c27-407a-afb5-d0439c374cbe', 'DatasetConsumptionConfig:train_images_0', 'bc619fbb-e949-42f5-9259-41301434c740', 'DatasetConsumptionConfig:train_images_1', '--test_sets', 'bc619fbb-e949-42f5-9259-41301434c740', 'DatasetConsumptionConfig:test_images_0', '--weights', 'DatasetConsumptionConfig:weights'])\n",
      "Initialize DatasetContextManager.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 116\n",
      "Set Dataset test_images_0's target path to /tmp/tmpid4hrhpc\n",
      "Set Dataset train_images_0's target path to /tmp/tmpsvtq87op\n",
      "Set Dataset train_images_1's target path to /tmp/tmpjtlqurtf\n",
      "Set Dataset weights's target path to /tmp/tmpa7ftzo_y\n",
      "Enter __enter__ of DatasetContextManager\n",
      "SDK version: azureml-core==1.17.0 azureml-dataprep==2.4.2. Session id: 8478d4a3-53dc-4f3f-abbc-62265916de08. Run id: model-yolov5-v-1-0_1604506223_8242fcca.\n",
      "Processing 'test_images_0'.\n",
      "Processing dataset FileDataset\n",
      "{\n",
      "  \"source\": [\n",
      "    \"('main_datastore', 'uploads/imageset-22-10-2020/car.png')\",\n",
      "    \"('main_datastore', 'uploads/imageset-22-10-2020/jayke.png')\",\n",
      "    \"('main_datastore', 'uploads/imageset-22-10-2020/shadyguy_dark.png')\",\n",
      "    \"('main_datastore', 'uploads/imageset-22-10-2020/skull.png')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"49fac13f-e0d8-4622-a4ac-f3634ec5e35b\",\n",
      "    \"name\": \"campaign-22-10-2020_images\",\n",
      "    \"version\": 1,\n",
      "    \"description\": \"Exported dataset as result of the finishing of labeling campaign campaign-22-10-2020\",\n",
      "    \"workspace\": \"Workspace.create(name='ExperimentationJayke', subscription_id='29d66431-a7ce-4709-93f7-3bdb01a243b3', resource_group='ExperimentationJayke')\"\n",
      "  }\n",
      "}\n",
      "Mounting test_images_0 to /tmp/tmpid4hrhpc.\n"
     ]
    }
   ],
   "source": [
    "from azurewrapper.train import perform_run\n",
    "from azureml.core.runconfig import TensorflowConfiguration\n",
    "\n",
    "weights = Dataset.get_by_name(workspace, name=\"YOLOV5\")\n",
    "\n",
    "run = perform_run(experiment, 'train.py', 'examples/yolov5', environment=environment,\n",
    "                  trainsets=trainsets, testsets=testsets, compute_target=compute_target,\n",
    "                  parameters={\n",
    "                      'weights': weights.as_named_input(f'weights').as_mount(),\n",
    "                  })\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toc_azureml",
   "language": "python",
   "name": "toc_azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
